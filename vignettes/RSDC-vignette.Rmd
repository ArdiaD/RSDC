---
title: "Regime-Switching Correlation Models with Time-Varying Transitions"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{RSDC-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
devtools::install("C:/Users/benj0/Dropbox/projet/_collaboration/project - correlation/Code BS/RSDC")
```

# Introdution

Modeling time-varying correlations between asset returns is crucial for portfolio management and risk analysis. Traditional approaches like Engle’s DCC model allow continuous correlation changes, but an alternative is to assume distinct regimes in which correlation matrices take fixed values that shift only when a new regime occurs. Regime-Switching Dynamic Correlation (RSDC) models (introduced by Pelletier, 2006) follow this approach: the covariance matrix is decomposed into volatilities and a correlation matrix $R_{S_t}$ that depends on a discrete state $S_t$. The correlation is constant within a regime but different across regimes, and transitions between regimes are governed by a Markov chain. This regime-switching framework can capture sudden shifts in correlation structure (for example, moving from a low-correlation “normal” market regime to a high-correlation “crisis” regime) better than smoothly changing models.

This R package `RSDC` implements Pelletier’s RSDC model and extends it by allowing time-varying transition probabilities (TVTP) driven by exogenous variables. In other words, instead of having fixed transition probabilities for the Markov chain, we let them be functions of observable covariates (e.g. risk indicators like VIX, climate risk indices, etc.). This is inspired by the broader literature on state-dependent Markov switching (e.g. Filardo, 1994), and has been found useful in practice – for instance, one study showed that a Pelletier-style constant correlation model with VIX-driven transition probabilities fit financial data best in their comparison. The incorporation of TVTP is one key novelty of our package. It means that the persistence of a correlation regime or the likelihood of switching can increase or decrease as a function of external variables (for example, a high climate-risk indicator might increase the probability of switching into a “crisis” correlation regime).

The package provides three flavors of correlation models:

-   **Constant Correlation (Single Regime)** – a baseline with no regime switching (all data share one static correlation matrix).

-   **Regime-Switching with Fixed Transitions** – the Markov-switching correlation model as in Pelletier (2006), with a fixed transition probability matrix (no exogenous inputs).

-   **Regime-Switching with TVTP (Time-Varying Transition Probabilities)** – our extended model where the Markov transition probabilities are dynamic functions of exogenous variables.

In all cases, we assume the input data are *standardized residuals* (e.g. returns scaled by their own volatility). In practice, you might first fit univariate GARCH models to each series to filter out volatility, and then feed the resulting standardized returns (with unit variance) into these correlation models. This way, the regime effects pertain purely to correlation dynamics, not changes in individual asset volatilities (which are handled separately).

Below, we outline the methodology for the regime-switching correlation models and then demonstrate the usage of the package with a simulation example. We also illustrate how to forecast dynamic covariance matrices and use them for portfolio allocation (minimum-variance and maximum-diversification portfolios).

# Methodology

## Regime-Switching Correlation Model

Assume we have $K$ assets. Let $U_t$ denote the $K$-dimensional vector of standardized residuals or returns at time $t$ (i.e., each component of $U_t$ has unit variance). We postulate that $U_t$ follows a mixture of $N$ correlation regimes. A latent state variable $S_t \in \{1, 2, \dots, N\}$ indicates the active regime at time $t$.

Conditional on $S_t = j$, the vector $U_t$ follows a multivariate normal distribution:

$$
U_t \mid (S_t = j) \sim \mathcal{N}(0, R_j), \qquad j = 1, \ldots, N.
$$

Each regime $j$ is associated with a correlation matrix $R_j$ of dimension $K \times K$. These matrices are symmetric, have ones on the diagonal, and contain off-diagonal correlation parameters $\rho^{(j)}$ to be estimated.

For example:

-   If $K = 3$, then each $R_j$ has 3 unique off-diagonal elements (i.e., pairwise correlations).
-   If $K = 2$, each $R_j$ has a single correlation coefficient.

These regime-specific correlations $\rho^{(j)}$ are unknown and must be estimated from the data.

In the special case where $N = 1$, the model reduces to a constant correlation model with a single matrix $R_1$, denoted the `"const"` model.

## Markov Switching Dynamics

We assume that the latent regime variable $(S_t)$ follows a Markov chain.

### Fixed Transition Model ("noX" case)

In the fixed-transition model, the transition probabilities are constant over time. Let $P$ be the $N \times N$ transition matrix, where:

$$
P_{ij} = \Pr(S_t = j \mid S_{t-1} = i).
$$

For the special case $N = 2$, we can write:

$$
P =
\begin{pmatrix}
p_{11} & 1 - p_{11} \\
1 - p_{22} & p_{22}
\end{pmatrix}.
$$

Here, $p_{11}$ is the probability of staying in regime 1 (i.e., regime 1's persistence), and $p_{22}$ is the probability of staying in regime 2. These values are estimated from the data. Our implementation directly estimates $p_{11}$ and $p_{22}$ in the two-regime case.

For $N > 2$, we estimate (or allow the user to supply) a full $N \times N$ transition matrix $P$ with each row summing to 1.

### Time-Varying Transition Probability Model ("tvtp" case)

In the time-varying case, the transition matrix evolves over time as a function of exogenous covariates $x_t$. We denote the transition matrix at time $t$ as $\Pi_t = [\pi_{ij}(t)]$, where:

$$
\pi_{ij}(t) = \Pr(S_t = j \mid S_{t-1} = i, x_t).
$$

These transition probabilities are parametrized using logistic regression. In the two-regime case, a convenient formulation is to model the *stay* probabilities $\pi_{ii}(t)$ using a logistic function of $x_t$:

$$
\pi_{ii}(t) = \Pr(S_t = i \mid S_{t-1} = i, x_t) = \frac{1}{1 + \exp(-x_t^\top \beta_i)}, \qquad i = 1,2,
$$

where $x_t$ is the exogenous input vector (possibly including a constant for an intercept), and $\beta_i$ is a vector of coefficients to be estimated for regime $i$. Each $\beta_i$ determines how the covariates influence the persistence of regime $i$.

For example, if an element of $\beta_1$ is positive, then an increase in the corresponding covariate increases $\pi_{11}(t)$, i.e., it makes regime 1 more persistent when it is currently active.

Given $\pi_{11}(t)$ and $\pi_{22}(t)$, the off-diagonal transition probabilities follow from the fact that each row of $\Pi_t$ must sum to 1:

$$
\Pi_t =
\begin{pmatrix}
\pi_{11}(t) & 1 - \pi_{11}(t) \\
1 - \pi_{22}(t) & \pi_{22}(t)
\end{pmatrix}.
$$

Thus: - $\pi_{12}(t) = 1 - \pi_{11}(t)$ - $\pi_{21}(t) = 1 - \pi_{22}(t)$

This formulation is aligned with the approach of time-varying Markov switching models such as those discussed in Pelletier (2006), although Pelletier's original model did not include exogenous drivers.

Our implementation generalizes this further: for any $N$, we use a multinomial logistic (softmax) specification. That is, for each current regime $i$, we model the vector of transition probabilities $(\pi_{i1}(t), \ldots, \pi_{iN}(t))$ as:

$$
\pi_{ij}(t) = \frac{\exp(x_t^\top \beta_{ij})}{\sum_{k=1}^N \exp(x_t^\top \beta_{ik})}, \qquad j = 1, \ldots, N.
$$

In the case of $N = 2$, this softmax reduces to the simpler logistic form above.

### Summary of Parameters

The full set of parameters to estimate in the TVTP model includes:

\- The logistic regression coefficients $\{\beta_i\}_{i=1}^N$

\- The correlation parameters for each regime $\{\rho^{(j)}\}_{j=1}^N$

If the fixed-transition ("noX") model is used instead, the parameters include the entries of the static transition matrix $P$ in place of the $\beta_i$'s.

We do **not** estimate means or variances of the time series; the residuals are assumed to have mean zero and unit variance. (Our package functions output placeholder values for regime means (set to 0) and volatilities (set to 1) for completeness, but these are not estimated in the likelihood.)

### Likelihood Inference via Hamilton Filter

We estimate the model parameters by **maximum likelihood**, using the **Hamilton filter** (i.e., the forward-backward algorithm for hidden Markov models) to evaluate the likelihood of the data given a set of parameters.

#### Filtering Steps

The Hamilton filter proceeds as follows:

-   **Prediction step:** Given the filtered probability from the previous time step,\
    $\xi_{i,t-1} = \Pr(S_{t-1} = i \mid \Omega_{t-1})$\
    (where $\Omega_{t-1}$ is the information available up to time $t-1$), we compute the *predictive probability* of being in state $j$ at time $t$:

    $$
    \Pr(S_t = j \mid \Omega_{t-1}) = \sum_{i=1}^N \xi_{i,t-1} \cdot \pi_{ij}(t),
    $$

    where $\pi_{ij}(t)$ is either a fixed transition probability $P_{ij}$ or a time-varying transition $\pi_{ij}(t)$, depending on the model.

-   **Update step:** We observe $U_t$ and compute its likelihood under each regime:

    $$
    f(U_t \mid S_t = j) = (2\pi)^{-K/2} |R_j|^{-1/2} \exp\left\{ -\frac{1}{2} U_t^\top R_j^{-1} U_t \right\}.
    $$

    Using Bayes' rule, we update the filtered probabilities:

    $$
    \xi_{j,t} = \Pr(S_t = j \mid \Omega_t) = \frac{\Pr(S_t = j \mid \Omega_{t-1}) \cdot f(U_t \mid S_t = j)}{\sum_{m=1}^N \Pr(S_t = m \mid \Omega_{t-1}) \cdot f(U_t \mid S_t = m)}.
    $$

-   **Initialization:** At $t = 1$, the filter is initialized using some $\xi_{i,0}$ (e.g., uniform or stationary distribution).

-   **Likelihood computation:** The **log-likelihood** is given by:

    $$
    \sum_{t=1}^T \log f(U_t \mid \Omega_{t-1}), \quad \text{where} \quad f(U_t \mid \Omega_{t-1}) = \sum_{j=1}^N \Pr(S_t = j \mid \Omega_{t-1}) \cdot f(U_t \mid S_t = j).
    $$

-   **Smoothing step (optional):** After filtering, a backward recursion can be applied to compute **smoothed probabilities** $\Pr(S_t = j \mid \Omega_T)$ using all information up to $T$.

#### Optimization Strategy

The likelihood surface can be irregular (with multiple local optima), so we use a **two-stage optimization**:

1.  A **global differential evolution** algorithm (`DEoptim`) for broad search.
2.  A **bounded local refinement** using **L-BFGS-B**.

This hybrid approach improves robustness but can be computationally intensive on large datasets.

### Model Variants

#### 1. Constant Correlation Model (`method = "const"`)

This is a special case where $N = 1$, i.e., no switching. We estimate a single correlation matrix $R_1$ over the full sample. This corresponds to a **constant conditional correlation** model. The log-likelihood has a closed-form (but we still use an optimizer for flexibility). This model serves as a **baseline**.

#### 2. Regime-Switching with Fixed Transitions (`method = "noX"`)

In this case, $N \ge 2$ and the transition matrix $P$ is time-invariant.

For $N = 2$, we estimate:

-   $p_{11}$: probability of staying in regime 1\
-   $p_{22}$: probability of staying in regime 2\
-   Off-diagonal terms follow: $p_{12} = 1 - p_{11}$ and $p_{21} = 1 - p_{22}$

Bounds are set to $[0.01, 0.99]$ to avoid degenerate regimes. This model, inspired by Pelletier (2006), captures regime shifts **without** exogenous information.

#### 3. Regime-Switching with Time-Varying Transitions (`method = "tvtp"`)

This is the **extended model**. It uses exogenous covariates $X \in \mathbb{R}^{T \times p}$ to drive time-varying transitions.

For each current state $i$, a logistic regression model is used:

$$
\pi_{ii}(t) = \frac{1}{1 + \exp(-x_t^\top \beta_i)}.
$$

-   If $\beta_{1}$ is large and positive, regime 1 becomes **more persistent** when $x_t$ is high.
-   If $\beta_{2}$ is large and negative, regime 2 becomes **less persistent** when $x_t$ is high.

In this setting, regime durations are influenced by observed variables (e.g., financial stress, news sentiment, etc.).

> **Note:** You must explicitly include an intercept in $X$ if desired (e.g., a column of 1s). The package does **not** add one automatically.

### Parameter Count and Model Comparison

-   **TVTP model:**
    -   $N \times p$ logistic coefficients ($\beta_i$ vectors)\
    -   $N$ correlation matrices\
-   **Fixed transition model:**
    -   $N(N - 1)$ probabilities in $P$ (with constraints)\
    -   $N$ correlation matrices

Model selection can be performed using BIC or other information criteria. The TVTP model typically fits better when the exogenous variables contain relevant regime-switching signals.

## Simulation Example

To illustrate how the package works, let’s create a simple synthetic example. We will simulate data from a 2-regime correlation model with time-varying transition probabilities that depend on a single exogenous variable. We’ll then fit various models to this data and compare the results.

### Simulation Setup

Suppose we have $K=2$ assets and $N=2$ regimes. We’ll design regime 1 to have a high correlation between the two assets, and regime 2 to have low correlation. Specifically, let the true correlation in regime 1 be $0.8$ and in regime 2 be $0.0$ (uncorrelated). Both regimes will have zero mean and unit variances for simplicity.

We introduce an exogenous variable $x_t$ that influences the switching: when $x_t$ is high (positive), the process will tend to stay or move into regime 1; when $x_t$ is low (negative), it will favor regime 2. We achieve this by setting the logistic coefficients as follows:

-   For regime 1:\
    $\beta_1 = (a_0, a_1) = (1.0,\; +2.0)$\
    So: $$
    \pi_{11}(t) = \frac{1}{1+\exp[-(1 + 2x_t)]}.
    $$

    This gives regime 1 a high persistence when $x_t$ is large (e.g. if $x_t=1$, $\pi_{11} \approx 0.95$), but low persistence when $x_t$ is very low (if $x_t=-1$, $\pi_{11} \approx 0.27$).

-   For regime 2:\
    $\beta_2 = (a_0, a_1) = (1.0,\; -2.0)$\
    So: $$
    \pi_{22}(t) = \frac{1}{1+\exp[-(1 - 2x_t)]}.
    $$

    This makes regime 2 sticky when $x_t$ is low (e.g. $x_t=-1$ gives $\pi_{22} \approx 0.95$) and very unstable when $x_t$ is high ($x_t=1$ gives $\pi_{22} \approx 0.27$).

In summary, $x_t$ can be thought of as a regime-driving factor: high values of $x_t$ promote the high-correlation regime 1, and low values promote the low-correlation regime 2.

For our simulation, we’ll generate $x_t$ as a smooth sinusoidal sequence to mimic an oscillating environment (so that the process will switch regimes a few times as $x_t$ rises and falls).

Using the function `f_simul_tvtp()` from our package, we simulate $T=500$ observations. Here’s the R code to perform the simulation:

```{r, simul setup}
library(RSDC) 
set.seed(123) 
T <- 500 
K <- 2
N <- 2 
# Create exogenous series: a sine wave between -1 and 1 
t_seq <- seq(0, 4 * pi, length.out = T) 

exog_var <- sin(t_seq) 
# Combine with a column of 1s for intercept 
X <- cbind(1, exog_var) 
# Define true coefficient arrays (N x N x p) 
p <- ncol(X) # which is 2 in this case (intercept + one covariate) 

beta_array <- array(0, dim = c(N, N, p)) 
# Set beta[i,i,] as defined above, and beta[i,j,] = 0 for i≠j 
beta_array[1, 1, ] <- c(1, 2) # beta1 (for staying in regime 1) 
beta_array[1, 2, ] <- c(0, 0) # not used (off-diagonal) 
beta_array[2, 2, ] <- c(1, -2) # beta2 (for staying in regime 2) 
beta_array[2, 1, ] <- c(0, 0) # not used 

# Define regime correlation matrices 
rho1 <- 0.8 # correlation in regime 1 
rho2 <- -0.6 # correlation in regime 2 
R1 <- matrix(c(1, rho1, rho1, 1), nrow = K) 
R2 <- matrix(c(1, rho2, rho2, 1), nrow = K) 
sigma_array <- array(0, dim = c(K, K, N)) 
sigma_array[, , 1] <- R1 
sigma_array[, , 2] <- R2 

# Regime means (zero for both regimes in this example) 
mu_matrix <- matrix(0, nrow = N, ncol = K) 

# Simulate the process 
sim_data <- f_simul_tvtp(n = T, 
                         X = X, 
                         beta = beta_array, 
                         mu = mu_matrix, 
                         sigma = sigma_array, 
                         N = N,
                         seed = 123) 
```

A few notes on the code: `f_simul_tvtp` returns a list with `sim_data$states` (the true latent regime sequence over time), `sim_data$observations` (the simulated $T \times K$ data matrix), and `sim_data$transition_matrices` (the realized transition matrix at each time step, which we won’t need here). We provided `sigma_array` as covariance matrices, but since we set unit variances, these are effectively correlation matrices for each regime.

Now, let’s verify the simulation qualitatively. We expect that when `exog_var` is high (around +1), the system will mostly be in regime 1 (high correlation), and when `exog_var` is low (around -1), it will be in regime 2. Indeed, we can check a few points:

```{r, head data}
# Quick check of states vs exogenous variable 
head(data.frame(Time = 1:10, 
                Exog = round(exog_var[1:10], 2), 
                State = sim_data$states[1:10])) 
tail(data.frame(Time = 200:209, 
                Exog = round(exog_var[200:209], 2), 
                State = sim_data$states[200:209])) 
```

We see that in early periods (where our sine wave starts at 0 and increases), we are more likely to be in state 1 as Exog becomes positive, and in later periods (as Exog goes back down toward -1) the state switches to 2. The majority of time spent in each regime corresponds to the half-cycles of the sine wave. This confirms that the simulation behaved as designed: the exogenous variable influences the regime dwelling times.

**Fitting the models:** Now suppose we as analysts observe only the `sim_data$observations` and the exogenous series `X`, and we want to fit our models to this data.

We will fit three models:

1\. A constant correlation model,

2\. A 2-regime model with fixed transition probabilities,

3\. A 2-regime model with TVTP using our provided `X`. We use the wrapper function `estimate_model()` for convenience (it will call the appropriate internal optimization routine for each case):

```{r, fit models}
residuals <- sim_data$observations # our data matrix 
# 1. Constant correlation (no regimes) 
fit_const <- estimate_model(method = "const", 
                            residuals = residuals, 
                            control = list(do_trace = FALSE))
# 2. Regime-switching with no exogenous variables (fixed P) 
fit_noX <- estimate_model(method = "noX", 
                          residuals = residuals, 
                          N = 2, 
                          control = list(do_trace = FALSE))
# 3. Regime-switching with time-varying transition probabilities 
fit_tvtp <- estimate_model(method = "tvtp", 
                           residuals = residuals, 
                           N = 2, 
                           X = X, 
                           control = list(do_trace = FALSE))
```

Each of these will return a list of estimated parameters and some diagnostics. Notably, `fit_tvtp` will contain `fit_tvtp$beta` (the estimated $2\times p$ matrix of logistic coefficients), `fit_tvtp$correlations` (an $N \times C$ matrix of estimated correlation parameters, where $C = K(K-1)/2$ is the number of unique pairwise correlations – here $C=1$ since $K=2$), and `fit_tvtp$log_likelihood`. Similarly, `fit_noX$transition_matrix` would give the estimated $P$ matrix for the Markov chain, and `fit_const$correlations` gives the single regime’s correlation estimate. Let’s inspect some results (rounded for clarity):

```{r, inspect results}
# Extract estimated correlation in each regime: 
round(fit_tvtp$correlations, 3) # Compare with true correlations (0.8 and -0.6) 
# Extract average transition matrix for TVTP model: 
round(fit_tvtp$transition_matrix, 3) 
# Estimated fixed transition matrix in noX model: 
round(fit_noX$transition_matrix, 3) 
# Extract beta tvtp: 
round(fit_tvtp$beta, 3)
```

We see that the **high-correlation regime** and **low-correlation regime** were successfully identified – the estimated correlations are close to the true values 0.8 and -0.6. Moreover, the TVTP model’s coefficients indicate the correct sign pattern (e.g. $\beta_1$ negative, $\beta_2$ positive for the covariate), aligning with how $x_t$ drives the transitions.

**Model comparison:** Because our simulated data genuinely followed the TVTP process, we expect the TVTP model to achieve a higher log-likelihood (and lower information criteria) than the misspecified alternatives. We can compare, for instance, the Bayesian Information Criterion (BIC) of the three fits:

```{r, BIC}
logLik_const <- fit_const$log_likelihood 
logLik_noX <- fit_noX$log_likelihood 
logLik_tvtp <- fit_tvtp$log_likelihood 
n <- nrow(residuals) 
# Parameter counts: 
k_const <- K*(K-1)/2 
# =1 parameter 
k_noX <- (2*(2-1)) + 2*(K*(K-1)/2) 
# = 2 + 2*1 = 4 parameters 
k_tvtp <- (2 * ncol(X)) + 2*(K*(K-1)/2) 
# = (2*2) + 2*1 = 6 parameters 
BIC_const <- log(n)*k_const - 2*logLik_const 
BIC_noX <- log(n)*k_noX - 2*logLik_noX 
BIC_tvtp <- log(n)*k_tvtp - 2*logLik_tvtp 
c(BIC_const, BIC_noX, BIC_tvtp) 
```

We find that BIC is smallest for the TVTP model (indicating best balance of fit and complexity). This shows that incorporating the exogenous signal $x_t$ materially improved the model’s explanatory power for the correlation changes.

## Forecasting Covariances and Portfolio Applications

After fitting a regime-switching model, we often want to use it to **forecast** future correlations or covariances. The package provides a function `f_forecast_cov()` that computes the predicted correlation matrix at each time step (in-sample or out-of-sample) using the filtered/smoothed probabilities. Essentially, it weights the regime correlation matrices by the probability of being in each regime at that time. Formally, if $\hat{\xi}_{j,t}$ is the probability of regime $j$ at $t$ (we use smoothed probabilities by default), and $r_j$ is the vector of pairwise correlations in regime $j$, then the predicted correlation vector is $\hat{r}_t = \sum_{j=1}^N \hat{\xi}_{j,t} \, r_j.$ This can be turned into a full predicted correlation matrix $\hat{R}_t$. If we also have forecasts of individual asset volatilities $\sigma_{k,t}$ (e.g. from GARCH models), we can then build the full covariance matrix forecast as $\hat{\Sigma}_t = D_t \hat{R}_t D_t$, where $D_t = \mathrm{diag}(\sigma_{1,t},...,\sigma_{K,t})$.

In our simulation example, we assumed unit variances throughout, so we don’t need an external volatility forecast. We can just use the model’s correlation predictions directly. The code below shows how to get the predicted correlations and covariances for our simulated data using the fitted TVTP model:

```{r, forecast}
forecast <- f_forecast_cov(method = "tvtp", 
                           N = 2, 
                           residuals = residuals, 
                           X = X, 
                           final_params = fit_tvtp, 
                           sigma_matrix = matrix(1, nrow = T, ncol = K), 
                           value_cols = 1:K,
                           out_of_sample = TRUE) 
# forecast is a list: 
names(forecast) 
```

Key elements in `forecast` include `forecast$predicted_correlations` (a matrix of the predicted pairwise correlations at each time $t$) and `forecast$cov_matrices` (a list of the full $K\times K$ covariance matrix at each $t$). In our case with $K=2$, `predicted_correlations` has just one column (the correlation between asset 1 and 2). We could plot this over time to see how the model’s predicted correlation varied. It should hover near 0.8 in the periods we know Regime 1 was likely, and near -0.6 in the other periods, with smooth transitions during uncertain times. In other words, it tracks the true correlation regime fairly well.

The `f_forecast_cov` function also returns the smoothed probabilities. We can plot it to ensure the probabilities oscillate like the sin wave and get a hint on the persistence of each regime:

```{r, plot probs}
plot(forecast$smoothed_probs[1, ], type = "l",
     col = "blue", lwd = 2,
     ylab = "Smoothed Probability",
     xlab = "Time",
     main = "Smoothed Probability of Regime 1")
```

Finally, the `f_forecast_cov` function computes the BIC (for the model used) and, if `out_of_sample=TRUE` was specified, it would handle splitting the data so that only the latter portion is used for forecasting (using parameters estimated on the first portion). In our example, we kept `out_of_sample=FALSE` to use the full series for illustration.

**Portfolio Allocation:** A primary motivation for modeling correlations dynamically is to improve portfolio construction. Knowing the current (or predicted) correlation structure can inform how to allocate assets to minimize risk or maximize diversification. This package includes two utility functions to compute **dynamic portfolio weights** given a time series of covariance forecasts:

-   `f_minvar()` – computes the **minimum-variance portfolio** (MVP) weights at each time step, given the covariance matrix forecast for that period. The MVP is the portfolio that achieves the lowest variance among all fully invested portfolios With standardized data (unit variances), this essentially depends on the correlation matrix. The function allows a `long_only` constraint (which we’ll use here, so all weights ≥ 0). Internally, it solves a quadratic program $w_t = \arg\min_w \{ w^\top \Sigma_t w : \mathbf{1}^\top w = 1, w \ge 0 \}$, which has the closed-form solution $w_t \propto \Sigma_t^{-1}\mathbf{1}$ in the unconstrained case (with long-only constraints, a QP solver is used).

-   `f_maxdiv()` – computes the **maximum diversification portfolio** (MDP) weights at each time. The diversification ratio is defined as $(\sum_k w_k \sigma_{k,t}) / \sqrt{w^\top \Sigma_t w}$ i.e. the ratio of the weighted average asset volatility to the portfolio volatility. Maximizing this tends to put more weight on less correlated (more diversifying) assets. With standardized variances, this simplifies to maximizing $\frac{\sum_k w_k}{\sqrt{w^\top R_t w}}$ since each $\sigma_{k,t}=1$ There’s no closed form; the function uses a nonlinear solver (Sequential Quadratic Programming via `Rsolnp`) to find $w_t$ for each $t$.

Let’s apply these to our forecast results. In our toy example the assets are symmetric, so we don’t expect dramatic changes in weights (they should be roughly 50/50 most of the time due to symmetry). But we can still demonstrate the usage:

```{r, build pfs}
# Compute dynamic minimum-variance and max-diversification weights 
port_minvar <- f_minvar(sigma_matrix = forecast$sigma_matrix, 
                        value_cols = 1:K, 
                        predicted_corr = forecast$predicted_correlations, 
                        y = residuals, 
                        rebalance = c("daily"),
                        long_only = TRUE)
port_maxdiv <- f_maxdiv(sigma_matrix = forecast$sigma_matrix, 
                        value_cols = 1:K, 
                        predicted_corr = forecast$predicted_correlations, 
                        y = residuals, 
                        rebalance = c("daily"),
                        long_only = TRUE) 
# Examine the first few weight vectors: 
head(port_minvar$weights, 5) 
head(port_maxdiv$weights, 5) 
```

The resulting `weights` matrices have dimensions $T \times K$ (here $500 \times 2$). For the MVP, since our two assets have equal variance and the same correlation structure, the weights turn out to be $(0.5, 0.5)$ at all times (the optimal solution is equal-weight in this symmetric case). For the MDP, we also have equal weights due to symmetry.

In a more general scenario with differing volatilities, correlation structures, or more assets, these weights would vary over time. For example, if one asset becomes extremely correlated with others, the max-diversification portfolio will reduce its weight to maintain a high diversification ratio; the min-variance portfolio would also re-balance away from highly correlated assets if others provide a diversification benefit. **(See potential paper with green vs brown or Fatma d**

**ata).**

The portfolio functions also return some performance metrics. For instance, `port_minvar$volatility` gives the **realized volatility** of the min-var portfolio (annualized based on the chosen rebalancing frequency). `port_maxdiv$diversification_ratios` gives the time series of realized diversification ratio achieved, and `port_maxdiv$mean_diversification` its average.

## Conclusion

In this vignette, we demonstrate how to use the `RSDC` package for modeling correlation dynamics with regime switching. We cover three model variants from a simple constant correlation model to a novel time-varying transition probability model that leverages exogenous information to improve correlation forecasts. Through a simulation example, we see that the TVTP model can capture regime shifts more accurately when an external signal is relevant, leading to better fit (as reflected in higher log-likelihood and lower BIC) compared to a model with static transition probabilities.

We also show how the fitted model outputs can be used to predict covariance matrices over time, and subsequently to construct dynamic portfolios such as minimum-variance or maximum-diversification portfolios. Incorporating changing correlation estimates into portfolio decisions can be crucial – for instance, during periods identified as “high correlation regime,” the benefits of diversification diminish, and a min-variance portfolio might not achieve as much risk reduction as in a low-correlation regime. By detecting such regime shifts (especially with the help of exogenous indicators), investors can adjust their strategies accordingly.

The `RSDC` package thus provides a flexible toolkit for researchers and practitioners to explore how regime-dependent correlations and external factors interact. Whether one is interested in the impact of economic indicators (like VIX, interest rates, climate risk indices, etc.) on market co-movements or simply wants a robust alternative to DCC models for correlation forecasting, this package offers an out-of-the-box solution. We encourage users to try it on their data – for example, to examine if adding a particular macro factor as an exogenous covariate meaningfully improves correlation forecasts and portfolio outcomes. We believe this approach, building on Pelletier’s (2006) regime-switching correlation model and extending it with state-dependent transitions, can yield valuable insights into the evolving interdependencies in financial markets
